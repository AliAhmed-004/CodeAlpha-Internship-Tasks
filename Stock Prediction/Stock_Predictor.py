# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p08k3IPrYDIAm2iq5i3t6EhFC65wAzdH

# Importing Basic Libraries
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

"""# Importing Data"""

stock_data = pd.read_csv('MSFT.csv')

stock_data

"""# Using Date and Column for the project"""

stock_data = stock_data[['Date', 'Close']]
stock_data

"""# Checking for Null Values"""

stock_data.info()

"""# Scaling and Splitting the Data"""

from sklearn.preprocessing import MinMaxScaler
import numpy as np

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(stock_data['Close'].values.reshape(-1, 1))

train_size = int(len(scaled_data) * 0.8) # 80 percent for training, 20 percent for testing
train_data = scaled_data[:train_size]
test_data = scaled_data[train_size:]

"""# Method to Convert String dates to DateTime objects
(since models don't like strings)
"""

import datetime

def string_to_datetime(string):
    splitted_date = string.split('-')
    year, month, day = int(splitted_date[0]), int(splitted_date[1]), int(splitted_date[2])
    return datetime.datetime(year = year, month = month, day = day)

"""## Testing the converter"""

date = string_to_datetime("2018-6-13")
date

"""# Converting the whole Date column to a DateTime object"""

stock_data['Date'] = stock_data['Date'].apply(string_to_datetime)
stock_data.info()

"""# Method to create datasets to train and test the model
This method creates 'Windows' of the dataset, meaning that if the prediction of a date is to be made, it will check 'time_stamp' dates back to make the prediction of the desired date. For example, if the price of the stock for 10th, 11th and 12th of July is 100, 200 and 150 respectively, and the 'time_stamp' is 3 then this data will be used to predict the stock price on 13th of july.
"""

def create_dataset(data, time_step=1):
    X, Y = [], []  # Initialize lists for storing input-output pairs
    for i in range(len(data) - time_step - 1):  # Loop through data with window size
        a = data[i:(i + time_step), 0]  # Extract a window of size 'time_step'
        X.append(a)  # Add this window to the list of inputs
        Y.append(data[i + time_step, 0])  # Add the next point as the target output
    return np.array(X), np.array(Y)  # Convert lists to numpy arrays and return

"""# Creating the Training and Testing Datasets"""

time_step = 60

X_train, y_train = create_dataset(train_data, time_step)
X_test, y_test = create_dataset(test_data, time_step)

# Reshape the data
X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

"""# Creating the Model"""

# importing necessary libraries for creating and training the model
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout

# Build the LSTM model
model = Sequential()
model.add(LSTM(units=50, return_sequences=True, input_shape=(time_step, 1)))
model.add(Dropout(0.2))
model.add(LSTM(units=50, return_sequences=True))
model.add(Dropout(0.2))
model.add(LSTM(units=50))
model.add(Dropout(0.2))
model.add(Dense(units=1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

"""# Training the Model
I stopped the training when the val loss was as low as I could get.
"""

model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))

"""# Making Predictions on Test Data"""

# Predicting on the test data
predicted_stock_price = model.predict(X_test)
predicted_stock_price = scaler.inverse_transform(predicted_stock_price)

plt.figure(figsize=(14, 5))
plt.plot(stock_data.index[-len(y_test):], scaler.inverse_transform(y_test.reshape(-1, 1)), color='red', label='Real MS Stock Price')
plt.plot(stock_data.index[-len(y_test):], predicted_stock_price, color='blue', label='Predicted MS Stock Price')
plt.title('Microsoft Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

"""# Checking RMSE"""

from sklearn.metrics import mean_squared_error

rmse = np.sqrt(mean_squared_error(y_test, predicted_stock_price))
print('Root Mean Squared Error:', rmse)

"""# Creating and Testing the Model on Unseen Test Data"""

data = pd.read_csv('synthetic_stock_data.csv')

# Ensure that the data is sorted by date
data = data.sort_values('Date')

# Use only the 'Close' prices for testing
closing_prices = data['Close'].values

# Reshape the data for MinMaxScaler
closing_prices = closing_prices.reshape(-1, 1)

# Load the MinMaxScaler used for training
scaler = MinMaxScaler(feature_range=(0, 1))

# Scale the closing prices
scaled_prices = scaler.fit_transform(closing_prices)

# Define time step
time_step = 60

# Prepare the test data
X_test, y_test = create_dataset(scaled_prices, time_step)

# Reshape for LSTM input
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)

# Make predictions
predicted_prices = model.predict(X_test)

# Inverse transform the predictions and actual prices
predicted_prices = scaler.inverse_transform(predicted_prices)
actual_prices = scaler.inverse_transform(y_test.reshape(-1, 1))

# Calculate RMSE
rmse = np.sqrt(mean_squared_error(actual_prices, predicted_prices))
print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')

# Optionally, plot the results for better visualization
import matplotlib.pyplot as plt

plt.figure(figsize=(14, 5))
plt.plot(actual_prices, label='Actual Prices', color='blue')
plt.plot(predicted_prices, label='Predicted Prices', color='red')
plt.title('Stock Price Prediction')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()
plt.show()

"""# Conclusion:
From the above tests, we can see that the LSTM is not the best approach to predict stock prices. This is because this approach cannot predict well on unseen data, meaning that the stock prices for future cannot  be reliably predicted with this model as there is too much discrepancy between the predictions and the actual values.
"""